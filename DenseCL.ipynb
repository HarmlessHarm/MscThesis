{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f342ddc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_encoder\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "%aimport modules\n",
    "from modules import DataScienceBowl\n",
    "from modules import Trainer\n",
    "from modules import CustomUnet\n",
    "from modules.Transforms import CombiTransform, ElasticTransform\n",
    "from modules.denseCL import DenseCL, ProjectionModule, DenseContrastiveLoss, GlobalContrastiveLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "892c8a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print('using cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using cpu')\n",
    "    \n",
    "\n",
    "# Set seeds\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d13af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4be21f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# class DenseCL(torch.nn.Module):\n",
    "    \n",
    "#     def __init__(self, lam=0.5, combination=None):\n",
    "#         super().__init__()\n",
    "        \n",
    "#         self.Lambda = lam\n",
    "        \n",
    "#         if combination is not None:\n",
    "#             self.transformer = CombiTransform(combination)\n",
    "#         else:\n",
    "#             self.transformer = CombiTransform()\n",
    "            \n",
    "#         self.encoder = get_encoder('resnet18', 3, 5, None)\n",
    "# #         self.encoder = get_encoder('resnet18', 3, 5, 'imagenet')\n",
    "#         self.encoder.layer4 = torch.nn.Identity()\n",
    "        \n",
    "#         self.project = DenseContrastiveModule()\n",
    "        \n",
    "# #         self.enc_proj = DenseContrastiveModule()\n",
    "        \n",
    "#         self.dense_loss = DenseContrastiveLoss()\n",
    "#         self.glob_loss = GlobalContrastiveLoss()\n",
    "        \n",
    "        \n",
    "#     def forward(self, image_1, image_2):\n",
    "        \n",
    "#         img_Q = self.transformer(image_1)\n",
    "#         img_pos = self.transformer(image_1)\n",
    "#         img_neg = self.transformer(image_2)\n",
    "        \n",
    "#         img_Q = self.encoder(img_Q)[-1]\n",
    "#         img_pos = self.encoder(img_pos)[-1]\n",
    "#         img_neg = self.encoder(img_neg)[-1]\n",
    "        \n",
    "#         dense_Q, glob_Q = self.project(img_Q)\n",
    "#         dense_pos, glob_pos = self.project(img_pos)\n",
    "#         dense_neg, glob_neg = self.project(img_neg)\n",
    "        \n",
    "#         d_loss = self.dense_loss(dense_Q, dense_pos, dense_neg)\n",
    "#         g_loss = self.glob_loss(glob_Q, glob_pos, glob_neg)\n",
    "        \n",
    "#         loss = (1 - self.Lambda) * g_loss + self.Lambda * d_loss\n",
    "        \n",
    "#         return loss\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# class DenseContrastiveModule(torch.nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         # Reduce bottleneck from 14x14x256 to 5x5x128\n",
    "#         self.densePool = torch.nn.MaxPool2d(2)\n",
    "#         self.projDense = torch.nn.Conv2d(256, 128, (3,3))\n",
    "        \n",
    "#         self.projGlobal = torch.nn.AvgPool2d(14)\n",
    "#         self.batchNorm = torch.nn.BatchNorm2d(256)\n",
    "#         pass\n",
    "    \n",
    "#     def forward(self, input):\n",
    "# #         encoded = self.encoder(input)[-1]\n",
    "#         normalized = self.batchNorm(input)\n",
    "        \n",
    "#         pooled = self.densePool(normalized)\n",
    "#         dense = self.projDense(pooled)\n",
    "#         glob = self.projGlobal(normalized)\n",
    "\n",
    "# #         loss = GlobalContrastiveLoss()\n",
    "# #         loss(glob, glob, glob)\n",
    "        \n",
    "#         return dense, glob\n",
    "\n",
    "    \n",
    "# #  Temperature\n",
    "# #  Lambda -> more to global\n",
    "# #  Bottleneck resolution (3,3 or 5,5)\n",
    "# #  Weight decay (optimizer) [0.0001] both contra and target task\n",
    "# #  Save for each 5 epochs the weights\n",
    "# #  Smaller learning rate (0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168c1d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class DenseContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, dense_img, dense_pos, dense_neg):\n",
    "        \n",
    "#         def reshape_bottleneck(x):\n",
    "#             return x.reshape(x.shape[0], x.shape[1], -1)\n",
    "    \n",
    "\n",
    "#         dense_img = reshape_bottleneck(dense_img)\n",
    "#         dense_pos = reshape_bottleneck(dense_pos)\n",
    "#         dense_neg = reshape_bottleneck(dense_neg)\n",
    "        \n",
    "#         assert dense_img.shape == dense_pos.shape and dense_img.shape == dense_neg.shape, \"input shapes should be the same\"\n",
    "        \n",
    "#         B = dense_img.shape[0]\n",
    "#         D = dense_img.shape[1]\n",
    "#         S = dense_img.shape[2]\n",
    "        \n",
    "#         temperature = 50\n",
    "        \n",
    "#         loss_sum = 0\n",
    "#         for i in range(S):\n",
    "#             query = dense_img[:,:,i]\n",
    "\n",
    "#             # Find most similar target vector\n",
    "#             dist = F.cosine_similarity(dense_pos, query.unsqueeze(-1), dim=1)\n",
    "#             max_i = torch.argmax(dist, dim=1)\n",
    "#             batch_pos = torch.cat([ torch.index_select(a, 1, i).unsqueeze(0) for a, i in zip(dense_pos, max_i) ])\n",
    "            \n",
    "#             dot_pos = torch.bmm(query.view(B,1,D), batch_pos.view(B,D,1))\n",
    "#             exp_pos = torch.exp(dot_pos / temperature)\n",
    "            \n",
    "#             dot_neg = torch.bmm(query.view(B,1,D), dense_neg.view(B,D,S))\n",
    "#             exp_neg = torch.exp(dot_neg/temperature)\n",
    "#             sum_neg = torch.sum(exp_neg, axis=2, keepdim=True)\n",
    "            \n",
    "#             loss_sum += -torch.log(exp_pos / (exp_pos + sum_neg))\n",
    "\n",
    "\n",
    "#         return torch.mean(loss_sum / S)\n",
    "            \n",
    "        \n",
    "# class GlobalContrastiveLoss(torch.nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#     def forward(self, global_img, global_pos, global_neg):\n",
    "    \n",
    "#         assert global_img.shape == global_pos.shape and global_img.shape == global_neg.shape, \"input shapes should be the same\"\n",
    "                \n",
    "#         B = global_img.shape[0]\n",
    "#         D = global_img.shape[1]\n",
    "        \n",
    "#         temperature = 50\n",
    "        \n",
    "# #         for i in range(S):\n",
    "#         query = global_img\n",
    "\n",
    "#         # Find most similar target vector\n",
    "#         dist = F.cosine_similarity(global_pos, query, dim=1)\n",
    "#         max_i = torch.argmax(dist, dim=1)\n",
    "#         batch_pos = torch.cat([ torch.index_select(a, 1, i).unsqueeze(0) for a, i in zip(global_pos, max_i) ])\n",
    "\n",
    "#         dot_pos = torch.bmm(query.view(B,1,D), batch_pos.view(B,D,1))\n",
    "#         exp_pos = torch.exp(dot_pos / temperature)\n",
    "\n",
    "#         dot_neg = torch.bmm(query.view(B,1,D), global_neg.view(B,D,1))\n",
    "#         exp_neg = torch.exp(dot_neg/temperature)\n",
    "#         sum_neg = torch.sum(exp_neg, axis=2, keepdim=True)\n",
    "\n",
    "#         global_loss = -torch.log(exp_pos / (exp_pos + sum_neg))\n",
    "\n",
    "#         return torch.mean(global_loss)\n",
    "\n",
    "    \n",
    "    \n",
    "# # - Weight decay in optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfd77f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transforms\n",
    "# TODO Separate Train and Test transforms\n",
    "transform = T.Compose([\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "#     T.ToTensor()\n",
    "#     T.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d9e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and split into train and test\n",
    "dataset = DataScienceBowl('data/data_science_train', transform=transform)\n",
    "\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "N = len(indices)\n",
    "# [ 0.3 train | 0.1 test | 0.1 validate | 0.5 unlab ]\n",
    "train_test, test_val, val_unlab = map(int, (0.3 * N, 0.4 * N, 0.5 * N))\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, indices[:train_test])\n",
    "test_dataset = torch.utils.data.Subset(dataset, indices[train_test:test_val])\n",
    "val_dataset = torch.utils.data.Subset(dataset, indices[test_val:val_unlab])\n",
    "unlabeled_dataset = torch.utils.data.Subset(dataset, indices[val_unlab:])\n",
    "\n",
    "print(len(unlabeled_dataset))\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "dataLoader_training = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataLoader_test = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataLoader_unlabeled = DataLoader(dataset=unlabeled_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dataLoader_validation = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7495fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm, trange\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "\n",
    "# model = DenseCL(combination=['color', 'random', 'noise'])\n",
    "model = DenseCL()\n",
    "model.to(device)\n",
    "\n",
    "# Use Binary Cross Entropy Loss and Stochastic Gradient Descent\n",
    "# criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "# epoch = 0\n",
    "progressbar = trange(epochs, desc=\"Progress\")\n",
    "\n",
    "training_loss = list()\n",
    "\n",
    "for epoch in progressbar:\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_losses = list()\n",
    "    batch_iter = tqdm(enumerate(dataLoader_unlabeled), \"Self Supervised Training\",\n",
    "                     total=len(dataLoader_unlabeled), leave=False)\n",
    "    \n",
    "    for i, sample in batch_iter:\n",
    "        x, y = sample.values()\n",
    "        \n",
    "        batch, target = x.to(device), y.to(device)\n",
    "        \n",
    "        B = batch.shape[0]\n",
    "        \n",
    "        if B % 2 != 0:\n",
    "            continue\n",
    "            \n",
    "        \n",
    "        image_1, image_2 = torch.split(batch, B//2)\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        loss = model(image_1, image_2)\n",
    "\n",
    "        epoch_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_iter.set_description(f'Training: (loss {loss.item():.4f})')\n",
    "        \n",
    "        \n",
    "    training_loss.append(np.mean(epoch_losses))\n",
    "    print(training_loss[-1])   \n",
    "    batch_iter.close()\n",
    "    \n",
    "    # Store model every 5 epochs for later use\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"storing model at {epoch}\")\n",
    "        model_name = f\"DenseCL_5x5_{epoch}_of_50_epochs_lr0_001.pt\"\n",
    "        torch.save(model.state_dict(), model_name)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd61e069",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'DenseCL_rand_5x5dense_50epochs_lr0_001.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19167eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(training_loss)\n",
    "# plt.plot(val_loss)\n",
    "# plt.hlines(test_loss, 0, len(train_loss) - 1, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c96b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = CustomUnet(model.encoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65663ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(unet.parameters(), lr=0.01)\n",
    "\n",
    "trainer = Trainer(model=unet,\n",
    "                 device=device,\n",
    "                 criterion=criterion,\n",
    "                 optimizer=optimizer,\n",
    "                 training_DataLoader=dataLoader_training,\n",
    "                 validation_DataLoader=dataLoader_validation,\n",
    "                 test_DataLoader=dataLoader_test,\n",
    "                 epochs=20,\n",
    "                 notebook=True,\n",
    "                 seed=42)\n",
    "\n",
    "train_loss, val_loss, lr, test_loss, test_iou = trainer.run_trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1761485",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test IoU', np.round(test_iou, 4))\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.hlines(test_loss, 0, len(train_loss) - 1, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59e31d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unet = CustomUnet(model.encoder)\n",
    "\n",
    "i = int(random.random() * len(test_dataset))\n",
    "# i = 55\n",
    "sample = train_dataset[i]\n",
    "img, target = sample.values()\n",
    "unet.eval()\n",
    "out = unet(img.unsqueeze(0).to(device))\n",
    "\n",
    "print(torch.max(out))\n",
    "print(torch.min(out))\n",
    "\n",
    "f,a = plt.subplots(1,2)\n",
    "\n",
    "a[0].imshow(out.squeeze(0).permute(1,2,0).detach().cpu().numpy())\n",
    "a[1].imshow(img.permute(1,2,0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f024cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "mask = F.sigmoid(out) >= 0.5\n",
    "\n",
    "mask = mask.squeeze(0).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "target = target.squeeze(0).type(torch.BoolTensor).detach().numpy()\n",
    "\n",
    "f, a = plt.subplots(1,2)\n",
    "\n",
    "a[0].imshow(mask)\n",
    "a[1].imshow(target)\n",
    "\n",
    "# plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ccc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "jaccard_score(mask.reshape(-1), target.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb5f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a = plt.subplots(1,2, figsize=(15,10))\n",
    "\n",
    "a[0].imshow((mask ^ target) & mask)\n",
    "a[1].imshow((mask ^ target) & target)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
